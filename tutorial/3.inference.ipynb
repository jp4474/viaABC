{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f71997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from systems import LotkaVolterra\n",
    "from lightning_module import PreTrainLightning\n",
    "from models import TSMVAE\n",
    "\n",
    "from inference_utils import load_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7a7352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model(\n",
    "    model_class=TSMVAE,\n",
    "    lightning_class=PreTrainLightning,\n",
    "    checkpoint_substr=\"TSMVAE\",\n",
    "    in_chans=2,\n",
    "    folder_name='/home/jp4474/latent-abc-smc/lotka_d64_ed32_6_4_4_4_ae_mask_0.15_noise_0.0',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6b0ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainLightning(\n",
       "  (model): TSMVAE(\n",
       "    (embedder): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (decoder_embed): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (decoder_norm): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
       "    (decoder_pred): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (linear): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:viaABC:Initializing ViaABC class\n",
      "INFO:viaABC:Model updated\n",
      "INFO:viaABC:Initialization complete\n",
      "INFO:viaABC:LatentABCSMC class initialized with the following parameters:\n",
      "INFO:viaABC:num_parameters: 2\n",
      "INFO:viaABC:Mu: [0 0]\n",
      "INFO:viaABC:Sigma: [10 10]\n",
      "INFO:viaABC:t0: 0\n",
      "INFO:viaABC:tmax: 15\n",
      "INFO:viaABC:time_space: [ 1.1  2.4  3.9  5.6  7.5  9.6 11.9 14.4]\n",
      "INFO:viaABC:pooling_method: no_cls\n",
      "INFO:viaABC:metric: pairwise_cosine\n"
     ]
    }
   ],
   "source": [
    "lotka_abc = LotkaVolterra(model=model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb283c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:viaABC:Starting ABC PMC run with Q Threshold: 0.99\n",
      "INFO:viaABC:Initialization (generation 0) started\n",
      "INFO:viaABC:Initialization completed in 36.11 seconds\n",
      "INFO:viaABC:Mean: [3.2584414  1.97469638]\n",
      "INFO:viaABC:Median: [1.73838092 1.66731045]\n",
      "INFO:viaABC:Variance: [6.46374809 1.62934223]\n",
      "INFO:viaABC:Generation 1 started\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  5.99it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.11074\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.87116\n",
      "INFO:viaABC:ABC-SMC: Simulations : 4286\n",
      "INFO:viaABC:Mean: [3.27587416 1.89151777]\n",
      "INFO:viaABC:Median: [1.79121897 1.59452189]\n",
      "INFO:viaABC:Variance: [6.11477868 1.23286953]\n",
      "INFO:viaABC:Generation 1 completed in 202.09 seconds\n",
      "INFO:viaABC:Generation 2 started\n",
      "100%|██████████| 1000/1000 [02:58<00:00,  5.61it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.10846\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.76539\n",
      "INFO:viaABC:ABC-SMC: Simulations : 4551\n",
      "INFO:viaABC:Mean: [2.91435163 1.82857775]\n",
      "INFO:viaABC:Median: [1.57745099 1.6091929 ]\n",
      "INFO:viaABC:Variance: [5.74047025 0.95845849]\n",
      "INFO:viaABC:Generation 2 completed in 214.20 seconds\n",
      "INFO:viaABC:Generation 3 started\n",
      "100%|██████████| 1000/1000 [03:30<00:00,  4.76it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.10692\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.81817\n",
      "INFO:viaABC:ABC-SMC: Simulations : 5376\n",
      "INFO:viaABC:Mean: [2.35606325 1.67444993]\n",
      "INFO:viaABC:Median: [1.41210262 1.47640899]\n",
      "INFO:viaABC:Variance: [4.03521466 0.9795665 ]\n",
      "INFO:viaABC:Generation 3 completed in 237.85 seconds\n",
      "INFO:viaABC:Generation 4 started\n",
      "100%|██████████| 1000/1000 [03:38<00:00,  4.58it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.09811\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.63176\n",
      "INFO:viaABC:ABC-SMC: Simulations : 5638\n",
      "INFO:viaABC:Mean: [1.73636059 1.617306  ]\n",
      "INFO:viaABC:Median: [1.25821277 1.38223439]\n",
      "INFO:viaABC:Variance: [2.07711188 1.0463815 ]\n",
      "INFO:viaABC:Generation 4 completed in 246.19 seconds\n",
      "INFO:viaABC:Generation 5 started\n",
      "100%|██████████| 1000/1000 [03:42<00:00,  4.50it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.06957\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.32618\n",
      "INFO:viaABC:ABC-SMC: Simulations : 5831\n",
      "INFO:viaABC:Mean: [1.18865674 1.65831184]\n",
      "INFO:viaABC:Median: [1.11958894 1.40356171]\n",
      "INFO:viaABC:Variance: [0.25033483 1.07341053]\n",
      "INFO:viaABC:Generation 5 completed in 257.40 seconds\n",
      "INFO:viaABC:Generation 6 started\n",
      "100%|██████████| 1000/1000 [04:42<00:00,  3.54it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.05736\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.37378\n",
      "INFO:viaABC:ABC-SMC: Simulations : 7533\n",
      "INFO:viaABC:Mean: [1.18532726 1.29478147]\n",
      "INFO:viaABC:Median: [1.04567688 1.21084679]\n",
      "INFO:viaABC:Variance: [0.12643452 0.42982779]\n",
      "INFO:viaABC:Generation 6 completed in 317.45 seconds\n",
      "INFO:viaABC:Generation 7 started\n",
      "100%|██████████| 1000/1000 [06:26<00:00,  2.59it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.04873\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.26553\n",
      "INFO:viaABC:ABC-SMC: Simulations : 10336\n",
      "INFO:viaABC:Mean: [1.18877135 1.07722097]\n",
      "INFO:viaABC:Median: [1.12162016 1.01184593]\n",
      "INFO:viaABC:Variance: [0.06754531 0.16354612]\n",
      "INFO:viaABC:Generation 7 completed in 421.96 seconds\n",
      "INFO:viaABC:Generation 8 started\n",
      "100%|██████████| 1000/1000 [11:12<00:00,  1.49it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.04161\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.23210\n",
      "INFO:viaABC:ABC-SMC: Simulations : 18191\n",
      "INFO:viaABC:Mean: [1.1100178  1.00548673]\n",
      "INFO:viaABC:Median: [1.10615289 0.9949997 ]\n",
      "INFO:viaABC:Variance: [0.0079649  0.03036169]\n",
      "INFO:viaABC:Generation 8 completed in 708.23 seconds\n",
      "INFO:viaABC:Generation 9 started\n",
      "100%|██████████| 1000/1000 [08:55<00:00,  1.87it/s]\n",
      "INFO:viaABC:ABC-SMC: Epsilon : 0.03989\n",
      "INFO:viaABC:ABC-SMC: Quantile : 0.21644\n",
      "INFO:viaABC:ABC-SMC: Simulations : 14515\n",
      "INFO:viaABC:Mean: [1.13069239 0.94718153]\n",
      "INFO:viaABC:Median: [1.12609537 0.94631058]\n",
      "INFO:viaABC:Variance: [0.00178584 0.00635661]\n",
      "INFO:viaABC:Generation 9 completed in 570.98 seconds\n",
      "INFO:viaABC:Generation 10 started\n",
      " 25%|██▌       | 251/1000 [01:52<05:35,  2.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlotka_abc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/latent-abc-smc/penv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/latent-abc-smc/viaABC.py:476\u001b[0m, in \u001b[0;36mviaABC.run\u001b[0;34m(self, num_particles, q_threshold, max_generations, k)\u001b[0m\n\u001b[1;32m    473\u001b[0m prev_meta_cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerations[generation_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Run generation\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m particles, weights, distances, simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_particles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_particles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprev_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_meta_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_epsilon\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m total_num_simulations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m simulations\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Process results\u001b[39;00m\n",
      "File \u001b[0;32m~/latent-abc-smc/viaABC.py:534\u001b[0m, in \u001b[0;36mviaABC._run_generation\u001b[0;34m(self, prev_particles, prev_weights, prev_cov, epsilon)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m accepted \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles:\n\u001b[0;32m--> 534\u001b[0m         theta, new_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_propose_particle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprev_particles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_particles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprev_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprev_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_cov\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m theta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/latent-abc-smc/viaABC.py:587\u001b[0m, in \u001b[0;36mviaABC._propose_particle\u001b[0;34m(self, prev_particles, prev_weights, prev_cov)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior_probability \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m    588\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(multivariate_normal\u001b[38;5;241m.\u001b[39mlogpdf(perturbed_params, mean\u001b[38;5;241m=\u001b[39mx, cov\u001b[38;5;241m=\u001b[39mprev_cov)) \n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m prev_particles\n\u001b[1;32m    590\u001b[0m ])\n\u001b[1;32m    591\u001b[0m log_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(prev_weights) \u001b[38;5;241m+\u001b[39m phi\n\u001b[1;32m    592\u001b[0m lse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(log_weights)))\n",
      "File \u001b[0;32m~/latent-abc-smc/viaABC.py:588\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prior_probability \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    587\u001b[0m phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m--> 588\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(\u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprev_cov\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m prev_particles\n\u001b[1;32m    590\u001b[0m ])\n\u001b[1;32m    591\u001b[0m log_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(prev_weights) \u001b[38;5;241m+\u001b[39m phi\n\u001b[1;32m    592\u001b[0m lse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(log_weights)))\n",
      "File \u001b[0;32m~/latent-abc-smc/penv/lib/python3.10/site-packages/scipy/stats/_multivariate.py:560\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.logpdf\u001b[0;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogpdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Log of the multivariate normal probability density function.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m     dim, mean, cov_object \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    562\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_quantiles(x, dim)\n",
      "File \u001b[0;32m~/latent-abc-smc/penv/lib/python3.10/site-packages/scipy/stats/_multivariate.py:418\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[0;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_Covariance(mean, cov)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# Before `Covariance` classes were introduced,\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` accepted plain arrays as `cov` and used the\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# following input validation. To avoid disturbing the behavior of\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# `multivariate_normal` when plain arrays are used, we use the\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# original input validation here.\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters_psd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     psd \u001b[38;5;241m=\u001b[39m _PSD(cov, allow_singular\u001b[38;5;241m=\u001b[39mallow_singular)\n",
      "File \u001b[0;32m~/latent-abc-smc/penv/lib/python3.10/site-packages/scipy/stats/_multivariate.py:480\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters_psd\u001b[0;34m(self, dim, mean, cov)\u001b[0m\n\u001b[1;32m    478\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(dim)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cov\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 480\u001b[0m     cov \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cov\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cov\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (dim, dim):\n\u001b[1;32m    482\u001b[0m     rows, cols \u001b[38;5;241m=\u001b[39m cov\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/latent-abc-smc/penv/lib/python3.10/site-packages/numpy/lib/twodim_base.py:293\u001b[0m, in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mabs\u001b[39m(k)\n\u001b[0;32m--> 293\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m         i \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lotka_abc.run(num_particles=1000, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
